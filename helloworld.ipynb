{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## è·å–å¤§æ¨¡å‹",
   "id": "5b69578a39592a1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T01:10:14.449076Z",
     "start_time": "2025-11-30T01:10:13.209228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import chain\n",
    "\n",
    "from langchain_classic.chains.summarize.refine_prompts import prompt_template\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from nbformat.v4 import output_from_msg\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"google/gemma-3n-e4b\",\n",
    "    openai_api_key=\"lm-studio\",\n",
    "    openai_api_base=\"http://localhost:1234/v1\"\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"10ä¸ªå­—å›ç­”æˆ‘ï¼šä»€ä¹ˆæ˜¯å¤§æ¨¡å‹\"))"
   ],
   "id": "2e190dba1b60e064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**æµ·é‡æ•°æ®è®­ç»ƒï¼Œæ™ºèƒ½ç”Ÿæˆï¼Œå¤šåŠŸèƒ½AIã€‚**\\n' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 19, 'total_tokens': 35, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'google/gemma-3n-e4b', 'system_fingerprint': 'google/gemma-3n-e4b', 'id': 'chatcmpl-5gl5racs1f3aimrbso15hb', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--64b46e53-9e52-49c3-a064-2c3622e0cff2-0' usage_metadata={'input_tokens': 19, 'output_tokens': 16, 'total_tokens': 35, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆ\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain: è¿™æ˜¯ä¸€ä¸ª LangChain ä¸­ç”¨äºå®šä¹‰ä¸€ç³»åˆ—æ­¥éª¤çš„é“¾ã€‚å®ƒå°† prompt å’Œ LLM è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„æµç¨‹ã€‚\n",
    "prompt | llm: è¿™ä½¿ç”¨äº† LangChain çš„ | è¿ç®—ç¬¦ï¼ˆå³ pipe æ“ä½œç¬¦ï¼‰ã€‚å®ƒå°† prompt å’Œ llm è¿æ¥èµ·æ¥ï¼Œè¡¨ç¤ºï¼š\n",
    "é¦–å…ˆä½¿ç”¨ prompt æ¨¡æ¿åˆ›å»º promptã€‚\n",
    "ç„¶åå°†ç”Ÿæˆçš„ prompt å‘é€ç»™ llmï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ OpenAI çš„ GPT æ¨¡å‹ï¼‰ã€‚\n",
    "LLM ä¼šæ ¹æ® prompt ç”Ÿæˆå›å¤ã€‚\n",
    "chain = ...: å°†æ„å»ºå¥½çš„é“¾èµ‹å€¼ç»™å˜é‡ chainã€‚"
   ],
   "id": "400c015d796a97d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T01:10:20.245621Z",
     "start_time": "2025-11-30T01:10:17.714480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"ä½ æ˜¯ä¸–ç•Œçº§çš„ä¸“å®¶\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ])\n",
    "\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\":\"ä¸¤å¥è¯ï¼Œå¤§æ¨¡å‹çš„langchainæ˜¯å•¥\"})\n",
    "print(message.content)"
   ],
   "id": "587e8cba2e7476bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºæ¡†æ¶ï¼Œæ—¨åœ¨ç®€åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„åº”ç”¨å¼€å‘ï¼Œæä¾›äº†ä¸€ç³»åˆ—å·¥å…·å’Œæ¨¡å—ï¼Œç”¨äºè¿æ¥ LLM ä¸å…¶ä»–æ•°æ®æºå’Œå·¥å…·ã€‚ ç®€å•æ¥è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ„å»ºåŸºäº LLM çš„åº”ç”¨çš„ç‘å£«å†›åˆ€ã€‚\n",
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ä½¿ç”¨è¾“å‡ºè§£æå™¨",
   "id": "3aa7bf221e8e6105"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:51:10.802530Z",
     "start_time": "2025-11-29T12:51:05.366354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser =JsonOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "message = chain.invoke({\"input\":\"å¤§æ¨¡å‹çš„langchainæ˜¯ä»€ä¹ˆï¼Ÿï¼Œç”¨JSONæ ¼å¼ï¼Œ5å¥è¯å†…å›ç­”ï¼Œé—®é¢˜ç”¨question,å›ç­”ç”¨answer\"})\n",
    "print(message)\n"
   ],
   "id": "8d046b0446c787ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Langchainæ˜¯ä»€ä¹ˆï¼Ÿ', 'answer': 'Langchain æ˜¯ä¸€ä¸ªæ—¨åœ¨ç®€åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åº”ç”¨å¼€å‘çš„æ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€ç³»åˆ—å·¥å…·ï¼Œç”¨äºè¿æ¥ LLM ä¸å…¶ä»–æ•°æ®æºå’Œå·¥å…·ï¼Œæ„å»ºå¤æ‚çš„é“¾å¼åº”ç”¨ã€‚æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬æ¨¡å‹é›†æˆã€æç¤ºç®¡ç†ã€é“¾ï¼ˆchainsï¼‰å’Œä»£ç†ï¼ˆagentsï¼‰ã€‚å®ƒæ—¨åœ¨æé«˜ LLM åº”ç”¨çš„å¯æ‰©å±•æ€§å’Œå®ç”¨æ€§ï¼Œé™ä½å¼€å‘éš¾åº¦ã€‚Langchain ä¿ƒè¿›äº† LLM åœ¨å„ç§åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆå’Œæ•°æ®åˆ†æã€‚'}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ä½¿ç”¨å‘é‡å­˜å‚¨",
   "id": "c0ee2f1526baa613"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T01:06:09.280118Z",
     "start_time": "2025-11-30T01:05:56.544607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===============================\n",
    "# 1. åŠ è½½ç½‘é¡µ\n",
    "# ===============================\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "url = \"https://www.gov.cn/zhengce/zhengceku/202504/content_7021191.htm\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url,\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"ç½‘é¡µåŠ è½½å®Œæˆï¼š\", len(docs), \"ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2. æ–‡æœ¬åˆ†å—\n",
    "# ===============================\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(docs)\n",
    "texts = [d.page_content for d in documents]\n",
    "\n",
    "print(\"æ–‡æœ¬åˆ†å—å®Œæˆï¼š\", len(texts), \"å—\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 3. LM Studio Embeddingï¼ˆè‡ªå®šä¹‰ç±»ï¼‰\n",
    "# ===============================\n",
    "import requests\n",
    "import numpy as np\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "class LMStudioEmbeddings(Embeddings):\n",
    "    def __init__(self, base_url=\"http://localhost:1234/v1\", model=\"text-embedding-nomic-embed-text-v1.5\"):\n",
    "        self.base_url = base_url\n",
    "        self.model = model\n",
    "\n",
    "    def embed_query(self, text: str):\n",
    "        payload = {\"input\": text, \"model\": self.model}\n",
    "        r = requests.post(f\"{self.base_url}/embeddings\", json=payload)\n",
    "        return r.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        vectors = []\n",
    "        for t in texts:\n",
    "            vectors.append(self.embed_query(t))\n",
    "        return vectors\n",
    "\n",
    "\n",
    "embedder = LMStudioEmbeddings(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    model=\"text-embedding-nomic-embed-text-v1.5\"\n",
    ")\n",
    "\n",
    "print(\"Embedding æ¨¡å‹å‡†å¤‡å®Œæˆ\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 4. ç”Ÿæˆå‘é‡ï¼ˆé€æ¡ï¼Œä¸èµ° LangChain çš„æ‰¹å¤„ç†ï¼‰\n",
    "# ===============================\n",
    "vectors = embedder.embed_documents(texts)\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "print(\"å‘é‡ç”Ÿæˆå®Œæˆï¼š\", vectors.shape)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 5. ä½¿ç”¨ FAISS æ„å»ºå‘é‡åº“ï¼ˆæ­£ç¡®æ ¼å¼ï¼‰\n",
    "# ===============================\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "text_embedding_pairs = list(zip(texts, vectors))\n",
    "\n",
    "vector_store = FAISS.from_embeddings(\n",
    "    text_embeddings=text_embedding_pairs,   # â† å…³é”®ï¼šä¼ äºŒå…ƒç»„åˆ—è¡¨\n",
    "    embedding=embedder,\n",
    "    metadatas=[{} for _ in texts],\n",
    ")\n",
    "\n",
    "print(\"å‘é‡åº“æ„å»ºå®Œæˆï¼\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 6. æ£€ç´¢\n",
    "# ===============================\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "query = \"è¿™ä¸ªæ”¿ç­–çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "\n",
    "# æ–°ç‰ˆæœ¬å†™æ³•\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "context = \"\\n\\n\".join([d.page_content for d in relevant_docs])\n",
    "\n",
    "print(\"æ£€ç´¢å®Œæˆï¼š\", len(relevant_docs), \"æ¡\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 7. ä½¿ç”¨ LM Studio LLM å›ç­”ï¼ˆChatOpenAIï¼‰\n",
    "# ===============================\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"google/gemma-3n-e4b\",\n",
    "    openai_api_key=\"lm-studio\",\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸“ä¸šæ”¿ç­–åˆ†æåŠ©æ‰‹ï¼Œè¯·åŸºäºç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œä¸å…è®¸ç¼–é€ å†…å®¹ã€‚\"),\n",
    "    (\"user\", \"\"\"\n",
    "é—®é¢˜ï¼š{question}\n",
    "\n",
    "ä¸Šä¸‹æ–‡ï¼š\n",
    "{context}\n",
    "\n",
    "è¯·æ€»ç»“å›ç­”ã€‚\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"question\": query,\n",
    "    \"context\": context\n",
    "})\n",
    "\n",
    "print(\"\\n================== æœ€ç»ˆå›ç­” ==================\\n\")\n",
    "print(response.content)"
   ],
   "id": "c80b27e18e362bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç½‘é¡µåŠ è½½å®Œæˆï¼š 1 ä¸ªæ–‡æ¡£\n",
      "æ–‡æœ¬åˆ†å—å®Œæˆï¼š 5 å—\n",
      "Embedding æ¨¡å‹å‡†å¤‡å®Œæˆ\n",
      "å‘é‡ç”Ÿæˆå®Œæˆï¼š (5, 768)\n",
      "å‘é‡åº“æ„å»ºå®Œæˆï¼\n",
      "æ£€ç´¢å®Œæˆï¼š 4 æ¡\n",
      "\n",
      "================== æœ€ç»ˆå›ç­” ==================\n",
      "\n",
      "è¿™ä¸ªæ”¿ç­–çš„ä¸»è¦å†…å®¹æ˜¯ï¼š**åœ¨2025å¹´5æœˆï¼ˆç¬¬äº”ä¸ªâ€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€ï¼‰ä»¥â€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€ä¸ºé‡ç‚¹ï¼Œå¼€å±•ä¸€ç³»åˆ—æ™®æ³•å®£ä¼ æ´»åŠ¨ï¼Œæ—¨åœ¨æé«˜ä¼ä¸šè¯šä¿¡å®ˆæ³•ç»è¥æ„è¯†å’Œèƒ½åŠ›ï¼ŒåŠ©åŠ›ä¼ä¸šé˜²èŒƒåŒ–è§£é£é™©ï¼Œä¿ƒè¿›ç»æµé«˜è´¨é‡å‘å±•ã€‚**\n",
      "\n",
      "å…·ä½“æ¥è¯´ï¼Œæ”¿ç­–å¼ºè°ƒï¼š\n",
      "\n",
      "*   **ä»¥ä¹ è¿‘å¹³æ³•æ²»æ€æƒ³ä¸ºæŒ‡å¯¼ï¼Œæ·±å…¥å­¦ä¹ å®£ä¼ æ°‘æ³•å…¸ã€‚**\n",
      "*   **é‡ç‚¹å¼€å±•â€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€æ´»åŠ¨ï¼Œå¹¶ç»“åˆå…¶ä»–é¢†åŸŸï¼ˆå¦‚æœºå…³ã€ä¹¡æ‘ã€ç¤¾åŒºç­‰ï¼‰å¼€å±•å®£ä¼ ã€‚**\n",
      "*   **çªå‡ºå­¦ä¹ å®£ä¼ ä¹ è¿‘å¹³æ³•æ²»æ€æƒ³ï¼Œé‡ç‚¹å¼ºè°ƒæ°‘æ³•å…¸çš„åŸºæœ¬åŸåˆ™å’Œç›¸å…³è§„å®šã€‚**\n",
      "*   **åŠ å¼ºä¸å„éƒ¨é—¨çš„åè°ƒé…åˆï¼Œå½¢æˆå¹¿æ³›å‚ä¸çš„æ™®æ³•å·¥ä½œæ ¼å±€ã€‚**\n",
      "*   **é¼“åŠ±åˆ›æ–°å®£ä¼ æ–¹å¼ï¼Œè¿ç”¨ä¼ ç»Ÿå’Œç°ä»£åŒ–æ‰‹æ®µç›¸ç»“åˆï¼Œæå‡å®£ä¼ æ•ˆæœã€‚**\n",
      "*   **å¼ºè°ƒåå¯¹å½¢å¼ä¸»ä¹‰ï¼Œæ³¨é‡æœåŠ¡ä¼ä¸šï¼Œä¸ç»™ä¼ä¸šå¢åŠ è´Ÿæ‹…ã€‚**\n",
      "\n",
      "æ€»è€Œè¨€ä¹‹ï¼Œè¯¥æ”¿ç­–æ—¨åœ¨é€šè¿‡å¹¿æ³›çš„å®£ä¼ æ´»åŠ¨ï¼Œè®©æ°‘æ³•å…¸æ·±å…¥ä¼ä¸šï¼Œæå‡ä¼ä¸šæ³•å¾‹æ„è¯†ï¼Œè¥é€ è‰¯å¥½çš„æ³•æ²»ç¯å¢ƒã€‚\n",
      "\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ragæ£€ç´¢å¢å¼ºç”Ÿæˆ\n",
    "| ç‰¹æ€§ | FAISS | Chroma | Pinecone |\n",
    "|------|-------|--------|----------|\n",
    "| **éƒ¨ç½²å½¢æ€** | æœ¬åœ°/è‡ªæ‰˜ç®¡ï¼ˆCPU/GPUï¼‰ | æœ¬åœ° Docker / Cloudï¼ˆè½»é‡ï¼‰ | å®Œå…¨æ‰˜ç®¡ SaaS |\n",
    "| **å¼€æº/å•†ä¸š** | å®Œå…¨å¼€æºï¼ˆMIT/Apacheï¼‰ | å¼€æºï¼ˆApache 2.0ï¼‰ | å•†ä¸šï¼ˆå…è´¹å±‚ï¼‰ |\n",
    "| **è§„æ¨¡** | é€‚åˆ **æ•°åƒä¸‡â€‘ä¸Šäº¿**ï¼ˆGPUï¼‰ | é€‚åˆ **å‡ ä¸‡â€‘å‡ ç™¾ä¸‡**ï¼ˆå•èŠ‚ç‚¹ï¼‰ | é€‚åˆ **æ•°åäº¿**ï¼ˆå¤šèŠ‚ç‚¹ï¼‰ |\n",
    "| **ç´¢å¼•ç±»å‹** | å¤šæ ·ï¼ˆFlat, IVF, HNSW, PQ, OPQâ€¦ï¼‰ | ä¸»è¦ HNSW + ç®€å• IVF | HNSW, IVFâ€‘FLAT, IVFâ€‘PQ, SPLADE ç­‰ |\n",
    "| **GPU åŠ é€Ÿ** | âœ…ï¼ˆCUDAï¼‰ | âŒï¼ˆCPUï¼‰ | âŒï¼ˆå®Œå…¨æ‰˜ç®¡ï¼Œå†…éƒ¨å¯èƒ½ä½¿ç”¨ GPUï¼‰ |\n",
    "| **å…ƒæ•°æ®è¿‡æ»¤** | éœ€è¦è‡ªè¡Œå®ç°ï¼ˆå¯ä¸ DB ç»„åˆï¼‰ | âœ… å†…ç½® | âœ… å†…ç½® |\n",
    "| **æŒä¹…åŒ–** | æ‰‹åŠ¨ï¼ˆ`write_index`ï¼‰ | è‡ªåŠ¨ï¼ˆSQLite/DuckDBï¼‰ | è‡ªåŠ¨ï¼ˆäº‘å­˜å‚¨ï¼‰ |\n",
    "| **å®‰å…¨/å¤šç§Ÿæˆ·** | è‡ªè¡Œæ­å»º | æœ¬åœ°å®‰å…¨ï¼Œäº‘ç‰ˆæœ‰é™ | å®Œæ•´ IAMã€VPCã€åŠ å¯† |\n",
    "| **æˆæœ¬** | ç¡¬ä»¶æˆæœ¬ï¼ˆè‡ªå·±ä¹°æœºå™¨ï¼‰ | ä½ï¼ˆæœ¬åœ°è¿è¡Œï¼‰ | æŒ‰é‡ä»˜è´¹ï¼ˆå…è´¹å±‚ï¼‰ |\n",
    "| **é€‚åˆäººç¾¤** | ç ”å‘ã€éœ€è¦æè‡´æ€§èƒ½ã€æˆ–å—åˆè§„çº¦æŸ | å¿«é€ŸåŸå‹ã€RAGã€å›¢é˜Ÿåä½œ | ç”Ÿäº§çº§å¤§è§„æ¨¡ã€éœ€è¦ SLA ä¸å¼¹æ€§ |\n",
    "\n",
    "FAISSï¼šæœ€çµæ´»ã€æœ€å¿«é€Ÿã€å®Œå…¨æœ¬åœ°ï¼Œå¯è‡ªè¡ŒæŒæ§æ‰€æœ‰ç»†èŠ‚ï¼›é€‚åˆæŠ€æœ¯å›¢é˜Ÿã€å¯¹æ€§èƒ½æœ‰è‹›åˆ»è¦æ±‚ã€æˆ–å—æ•°æ®åˆè§„é™åˆ¶çš„åœºæ™¯ã€‚\n",
    "Chromaï¼šè½»é‡ã€å¼€ç®±å³ç”¨ã€ä¸ LLM æ¡†æ¶é«˜åº¦é›†æˆï¼Œç‰¹åˆ«é€‚åˆ RAG åŸå‹å¼€å‘å’Œä¸­å°è§„æ¨¡å‘é‡æ£€ç´¢ã€‚\n",
    "Pineconeï¼šæ‰˜ç®¡äº‘æœåŠ¡ï¼Œæä¾›å¼¹æ€§ä¼¸ç¼©ã€å¼ºå¤§çš„å®‰å…¨ä¸è¿ç»´èƒ½åŠ›ï¼Œæ˜¯ å¤§è§„æ¨¡ã€ç”Ÿäº§ç¯å¢ƒ çš„é¦–é€‰ã€‚\n",
    "\n"
   ],
   "id": "1c7852a9fd85ffa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T02:23:05.380057Z",
     "start_time": "2025-11-30T02:22:53.705151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1ï¸âƒ£ å¯¼å…¥ PromptTemplateï¼ˆç”¨äºæŠŠæ¨¡æ¿å­—ç¬¦ä¸²æ¸²æŸ“æˆ Prompt å¯¹è±¡ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2ï¸âƒ£ åˆ›å»ºæ£€ç´¢å™¨ï¼ˆRetrieverï¼‰\n",
    "#    - vector_storeï¼šå·²ç»æ„å»ºå¥½çš„å‘é‡æ•°æ®åº“ï¼ˆå¦‚ FAISSã€Chromaã€Pinecone ç­‰ï¼‰\n",
    "#    - as_retriever() ä¼šæŠŠå‘é‡åº“åŒ…è£…æˆ LangChain æ ‡å‡†çš„ Retriever æ¥å£\n",
    "# ------------------------------------------------------------\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3ï¸âƒ£ é…ç½®æ£€ç´¢å™¨çš„æœç´¢å‚æ•°\n",
    "#    - search_kwargs æ˜¯ä¸€ä¸ª dictï¼Œé‡Œé¢çš„é”®å€¼ä¼šç›´æ¥ä¼ ç»™åº•å±‚çš„\n",
    "#      å‘é‡åº“çš„ç›¸ä¼¼åº¦æœç´¢å‡½æ•°\n",
    "#    - k è¡¨ç¤º **è¿”å›æœ€ç›¸ä¼¼çš„å‰ k æ¡æ–‡æ¡£**ï¼ˆè¿™é‡Œå– 3 æ¡ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4ï¸âƒ£ æ‰§è¡Œæ£€ç´¢\n",
    "#    - invoke() æ¥æ”¶ä¸€ä¸ªæŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œè¿”å›æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨\n",
    "#    - æ¯æ¡æ–‡æ¡£é€šå¸¸æ˜¯ LangChain çš„ Document å¯¹è±¡ï¼ŒåŒ…å«\n",
    "#      .page_contentï¼ˆæ­£æ–‡ï¼‰å’Œ .metadataï¼ˆå…ƒä¿¡æ¯ï¼‰ç­‰å±æ€§\n",
    "# ------------------------------------------------------------\n",
    "docs = retriever.invoke(\"æ°‘æ³•å…¸è¿›ä¼ä¸šæ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5ï¸âƒ£ ç¼–å†™ LLM æç¤ºæ¨¡æ¿ï¼ˆPromptTemplateï¼‰\n",
    "#    - è¿™é‡Œä½¿ç”¨å¤šè¡Œå­—ç¬¦ä¸²ï¼ˆ\"\"\"ï¼‰å®šä¹‰äº†ä¸€ä¸ªâ€œæŒ‡ä»¤å¼â€æç¤º\n",
    "#    - {info} ä¸ {question} æ˜¯å ä½ç¬¦ï¼Œç¨åä¼šè¢«çœŸå®å†…å®¹æ›¿æ¢\n",
    "# ------------------------------------------------------------\n",
    "prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚\n",
    "ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚\n",
    "å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤â€æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜â€ã€‚\n",
    "å·²çŸ¥ä¿¡æ¯ï¼š{info}\n",
    "ç”¨æˆ·é—®ï¼š\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6ï¸âƒ£ æŠŠæ¨¡æ¿å­—ç¬¦ä¸²è½¬æˆ PromptTemplate å¯¹è±¡\n",
    "#    - from_template() ä¼šè‡ªåŠ¨æŠŠå ä½ç¬¦è§£æä¸ºæ¨¡æ¿å˜é‡\n",
    "# ------------------------------------------------------------\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7ï¸âƒ£ ç”¨æ£€ç´¢åˆ°çš„æ–‡æ¡£å’Œç”¨æˆ·æé—®æ¸²æŸ“ Prompt\n",
    "#    - info å‚æ•°å¡«å…¥æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨ï¼ˆLangChain ä¼šæŠŠåˆ—è¡¨\n",
    "#      è‡ªåŠ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¸¸è§åšæ³•æ˜¯å°†æ¯ç¯‡æ–‡æ¡£çš„ .page_content\n",
    "#      ç”¨æ¢è¡Œæˆ–åˆ†éš”ç¬¦æ‹¼æ¥èµ·æ¥ï¼‰\n",
    "#    - question å‚æ•°å¡«å…¥åŸå§‹ç”¨æˆ·æé—®\n",
    "# ------------------------------------------------------------\n",
    "prompt = template.format(info=docs, question=\"æ°‘æ³•å…¸è¿›ä¼ä¸šæ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8ï¸âƒ£ è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç­”æ¡ˆ\n",
    "#    - llm å¿…é¡»æ˜¯å·²ç»å®ä¾‹åŒ–çš„ LLM å¯¹è±¡ï¼ˆOpenAIã€Claudeã€ChatGLMâ€¦\n",
    "#      ä»»æ„æ”¯æŒ .invoke() æ¥å£çš„æ¨¡å‹ï¼‰\n",
    "#    - .invoke() æ¥æ”¶æ¸²æŸ“å¥½çš„ Promptï¼Œè¿”å›ä¸€ä¸ªåŒ…å«\n",
    "#      .contentï¼ˆç”Ÿæˆæ–‡æœ¬ï¼‰çš„å“åº”å¯¹è±¡\n",
    "# ------------------------------------------------------------\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9ï¸âƒ£ æ‰“å°æ¨¡å‹çš„å›ç­”\n",
    "# ------------------------------------------------------------\n",
    "print(response.content)\n"
   ],
   "id": "7f0a89771379c7d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œ2025å¹´çš„â€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€å·¥ä½œæ–¹æ¡ˆä»¥â€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€ä¸ºé‡ç‚¹ï¼Œæ—¨åœ¨ç»„ç»‡å¼€å±•æ°‘æ³•å…¸ç³»åˆ—æ™®æ³•å®£ä¼ ï¼Œå…¨é¢æé«˜ä¼ä¸šè¯šä¿¡å®ˆæ³•ç»è¥æ„è¯†å’Œèƒ½åŠ›ï¼ŒåŠ©åŠ›ä¼ä¸šé˜²èŒƒåŒ–è§£é£é™©ã€ä¾æ³•ç»´æŠ¤è‡ªèº«åˆæ³•æƒç›Šï¼Œä¸ºä¿ƒè¿›ç»æµé«˜è´¨é‡å‘å±•è¥é€ è‰¯å¥½æ³•æ²»ç¯å¢ƒã€‚\n",
      "\n",
      "å…·ä½“æ¥è¯´ï¼Œâ€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€æ´»åŠ¨è¦ï¼š\n",
      "* åšæŒä»¥ä¹ è¿‘å¹³æ–°æ—¶ä»£ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ€æƒ³ä¸ºæŒ‡å¯¼ï¼Œæ·±å…¥å­¦ä¹ å®£ä¼ æ°‘æ³•å…¸ã€‚\n",
      "* é‡ç‚¹å­¦ä¹ å®£ä¼ å¹³ç­‰ã€è‡ªæ„¿ã€å…¬å¹³ã€è¯šä¿¡ç­‰åŸºæœ¬åŸåˆ™ï¼Œä»¥åŠç›¸å…³è§„å®šã€‚\n",
      "* é‡ç‚¹å®£ä¼ ä¼˜åŒ–è¥å•†ç¯å¢ƒã€çŸ¥è¯†äº§æƒä¿æŠ¤å’Œç§‘æŠ€åˆ›æ–°ã€æ„å»ºå’Œè°åŠ³åŠ¨å…³ç³»ã€ä¸­å›½ä¼ä¸šâ€œèµ°å‡ºå»â€ç­‰ä¸ä¼ä¸šç”Ÿäº§ç»è¥å¯†åˆ‡ç›¸å…³çš„æ³•å¾‹æ³•è§„ã€‚\n",
      "\n",
      "å› æ­¤ï¼Œæ°‘æ³•å…¸è¿›ä¼ä¸šå°±æ˜¯ä»¥å®£ä¼ å’Œè´¯å½»å®æ–½æ°‘æ³•å…¸ä¸ºæ ¸å¿ƒï¼Œå°†æ³•å¾‹å®£ä¼ å·¥ä½œå»¶ä¼¸åˆ°ä¼ä¸šå†…éƒ¨ï¼Œå¸®åŠ©ä¼ä¸šæ›´å¥½åœ°äº†è§£å’Œè¿ç”¨æ°‘æ³•å…¸ï¼Œä»è€Œä¿ƒè¿›ä¼ä¸šçš„å¥åº·å‘å±•ã€‚\n",
      "\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6 ä½¿ç”¨Agent\n",
    "```py\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"  # â† è¿™æ˜¯ docstring\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "```\n",
    "\n",
    "å½“è¿™ä¸ªå·¥å…·è¢«ä¼ ç»™ agent æ—¶ï¼ŒLangChain ä¼šç”Ÿæˆå¦‚ä¸‹çš„å·¥å…·å®šä¹‰ï¼š\n",
    "```json\n",
    "{\n",
    "  \"name\": \"retrieve_context\",\n",
    "  \"description\": \"Retrieve information to help answer a query.\",  // â† ä» docstring æå–\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"query\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The query to search for\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "invokeæ ¼å¼ï¼š\n",
    "```python\n",
    "# âœ… ä½¿ç”¨æ¶ˆæ¯æ ¼å¼\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸çš„å«ä¹‰ï¼Ÿ\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "# ä¼˜åŠ¿ï¼š\n",
    "# 1. âœ… æ”¯æŒå¤šè½®å¯¹è¯\n",
    "# 2. âœ… ä¿ç•™æ¶ˆæ¯å†å²\n",
    "# 3. âœ… æ˜ç¡®è§’è‰²èº«ä»½ï¼ˆuser/assistant/systemï¼‰\n",
    "# 4. âœ… ä¸ LLM API æ ‡å‡†æ ¼å¼å…¼å®¹\n",
    "```\n",
    "\n",
    "```python\n",
    "# ç¬¬ä¸€è½®å¯¹è¯\n",
    "result1 = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸çš„å«ä¹‰ï¼Ÿ\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "# è·å–ç¬¬ä¸€ä¸ªç­”æ¡ˆ\n",
    "assistant_response = result1[\"messages\"][-1].content\n",
    "\n",
    "# ç¬¬äºŒè½®å¯¹è¯ï¼šåŸºäºç¬¬ä¸€ä¸ªç­”æ¡ˆç»§ç»­æé—®\n",
    "# æ¶ˆæ¯å†å²ä¼šä¿ç•™ï¼Œagent èƒ½ç†è§£ä¸Šä¸‹æ–‡\n",
    "result2 = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸çš„å«ä¹‰ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_response},\n",
    "        {\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "# result2 ä¸­ï¼Œagent çŸ¥é“ä¸Šä¸‹æ–‡ï¼Œèƒ½ç»™å‡ºæ›´ç›¸å…³çš„ç­”æ¡ˆ\n",
    "```"
   ],
   "id": "76921760b3119356"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T03:36:08.122249Z",
     "start_time": "2025-11-30T03:35:54.228889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== ç¬¬ä¸€éƒ¨åˆ†ï¼šå®šä¹‰ Retriever å·¥å…· =====\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "# @tool è£…é¥°å™¨ï¼šå°†å‡½æ•°è½¬æ¢ä¸º LangChain å·¥å…·\n",
    "# response_format=\"content_and_artifact\"ï¼šè®¾ç½®è¿”å›æ ¼å¼\n",
    "#   - \"content\"ï¼šå‘é€ç»™ LLM çš„æ–‡æœ¬è¡¨ç¤º\n",
    "#   - \"artifact\"ï¼šåŸå§‹æ–‡æ¡£å¯¹è±¡ï¼ˆä¿ç•™å…ƒæ•°æ®ï¼‰ï¼Œä¾›åº”ç”¨ä½¿ç”¨\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"è·å–ä¿¡æ¯ï¼Œå›ç­”é—®é¢˜\"\"\"\n",
    "\n",
    "    # ä»å‘é‡æ•°æ®åº“ä¸­ç›¸ä¼¼æ€§æœç´¢\n",
    "    # ä½¿ç”¨ç»™å®šçš„ query æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ k=2 ä¸ªæ–‡æ¡£\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "    # å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ä¾› LLM ä½¿ç”¨\n",
    "    # æ¯ä¸ªæ–‡æ¡£åŒ…å«æºä¿¡æ¯å’Œå†…å®¹\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "\n",
    "    # è¿”å›å…ƒç»„ï¼š(æ ¼å¼åŒ–æ–‡æœ¬, åŸå§‹æ–‡æ¡£)\n",
    "    # - æ ¼å¼åŒ–æ–‡æœ¬ï¼šLLM ä¼šçœ‹åˆ°è¿™ä¸ªå†…å®¹\n",
    "    # - åŸå§‹æ–‡æ¡£ï¼šåº”ç”¨ä»£ç å¯ä»¥è®¿é—®å…ƒæ•°æ®\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "# ===== ç¬¬äºŒéƒ¨åˆ†ï¼šåˆ›å»º LLM æ¨¡å‹ =====\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åˆå§‹åŒ–æœ¬åœ° Gemma æ¨¡å‹ï¼ˆé€šè¿‡ LM Studioï¼‰\n",
    "# æ³¨æ„ï¼šè¿™é‡Œé…ç½®çš„æ˜¯æœ¬åœ°æ¨¡å‹ï¼Œä¸æ˜¯ OpenAI å®˜æ–¹ API\n",
    "llm = ChatOpenAI(\n",
    "    model=\"google/gemma-3n-e4b\",        # ä½¿ç”¨çš„æ¨¡å‹ ID\n",
    "    openai_api_key=\"lm-studio\",          # API å¯†é’¥ï¼ˆæœ¬åœ°å¯è®¾ä¸ºä»»æ„å€¼ï¼‰\n",
    "    openai_api_base=\"http://localhost:1234/v1\",  # æœ¬åœ°æœåŠ¡åœ°å€\n",
    "    temperature=0                         # æ¸©åº¦ä¸º 0ï¼šç¡®å®šæ€§è¾“å‡ºï¼Œä¸ä½¿ç”¨éšæœºæ€§\n",
    ")\n",
    "\n",
    "\n",
    "# ===== ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ›å»º Agent =====\n",
    "\n",
    "# create_agentï¼šLangChain v1 æ ‡å‡† agent åˆ›å»ºå‡½æ•°\n",
    "# åŸºäº ReAct å¾ªç¯ï¼ˆæ¨ç† + è¡ŒåŠ¨ï¼‰\n",
    "agent = create_agent(\n",
    "    model=llm,                               # ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ LLM\n",
    "    tools=[retrieve_context],                # å·¥å…·åˆ—è¡¨ï¼šåŒ…å«æˆ‘ä»¬çš„ retriever å·¥å…·\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„æ°‘æ³•å…¸åŠ©æ‰‹ã€‚\", # ç³»ç»Ÿæç¤ºè¯\n",
    ")\n",
    "\n",
    "# Agent æ‰§è¡Œæµç¨‹ï¼š\n",
    "# 1. æ¥æ”¶ç”¨æˆ·è¾“å…¥\n",
    "# 2. è°ƒç”¨ llm è¿›è¡Œæ¨ç†\n",
    "# 3. LLM å†³å®šæ˜¯å¦è°ƒç”¨ retrieve_context å·¥å…·\n",
    "# 4. å¦‚æœè°ƒç”¨ï¼Œè·å–æ£€ç´¢ç»“æœ\n",
    "# 5. åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
    "# 6. é‡å¤ 2-5ï¼Œç›´åˆ° LLM è®¤ä¸ºå¯ä»¥æä¾›æœ€ç»ˆç­”æ¡ˆ\n",
    "\n",
    "\n",
    "# ===== ç¬¬å››éƒ¨åˆ†ï¼šæ‰§è¡Œ Agent =====\n",
    "\n",
    "# # è°ƒç”¨ agentï¼Œä¼ å…¥ç”¨æˆ·é—®é¢˜\n",
    "# result = agent.invoke({\n",
    "#     \"messages\": [\n",
    "#         {\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ\"}\n",
    "#     ]\n",
    "# })\n",
    "# print( result[\"messages\"][-1].content)\n",
    "\n",
    "# âœ… æ–¹å¼ 1: ä½¿ç”¨ stream æŸ¥çœ‹è¯¦ç»†è¿‡ç¨‹\n",
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # æ¯ä¸ª chunk æ˜¾ç¤ºå½“å‰çŠ¶æ€\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent å›å¤: {latest_message.content}\")\n",
    "    elif hasattr(latest_message, 'tool_calls') and latest_message.tool_calls:\n",
    "        # æ˜¾ç¤ºè°ƒç”¨çš„å·¥å…·\n",
    "        for tool_call in latest_message.tool_calls:\n",
    "            print(f\"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}\")\n",
    "            print(f\"   å‚æ•°: {tool_call['args']}\")\n",
    "\n",
    "# result æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« agent çš„è¾“å‡º\n",
    "# å¯ä»¥é€šè¿‡ result[\"messages\"][-1].content è·å–æœ€ç»ˆç­”æ¡ˆ"
   ],
   "id": "45d02b20d7c21c1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent å›å¤: æ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "Agent å›å¤: \n",
      "\n",
      "Agent å›å¤: Source: {}\n",
      "Content: å…šå§”å®£ä¼ éƒ¨ã€å¸æ³•è¡Œæ”¿éƒ¨é—¨è¦å……åˆ†å‘æŒ¥ç‰µå¤´æŠ“æ€»ä½œç”¨ï¼ŒåŠ å¼ºä¸è¡Œä¸šä¸»ç®¡éƒ¨é—¨çš„åè°ƒé…åˆï¼ŒæŠŠæ¡æ´»åŠ¨é‡ç‚¹å†…å®¹å’ŒèŠ‚å¥ï¼Œæ¨åŠ¨æ°‘æ³•å…¸æ™®æ³•å„é¡¹å·¥ä½œè½å®è½ç»†ã€‚è®¤çœŸè½å®é¢†å¯¼å¹²éƒ¨åº”çŸ¥åº”ä¼šå…šå†…æ³•è§„å’Œå›½å®¶æ³•å¾‹æ¸…å•åˆ¶åº¦ã€â€œè°æ‰§æ³•è°æ™®æ³•â€æ™®æ³•è´£ä»»ã€åª’ä½“å…¬ç›Šæ™®æ³•è´£ä»»ï¼Œå‘æŒ¥å¥½å„ç±»è¡Œä¸šåä¼šã€å•†ä¼šä»¥åŠâ€œæ³•å¾‹æ˜ç™½äººâ€ã€æ™®æ³•è®²å¸ˆå›¢ã€æ™®æ³•å¿—æ„¿è€…ç­‰å…¬ç›Šæ™®æ³•é˜Ÿä¼ä½œç”¨ï¼Œå½¢æˆä¸Šä¸‹è”åŠ¨ã€å¹¿æ³›å‚ä¸ã€å…±åŒè¡ŒåŠ¨çš„æ°‘æ³•å…¸æ™®æ³•å·¥ä½œæ ¼å±€ã€‚åšæŒâ€œå°åˆ‡å£ã€å¤§ä¸»é¢˜â€ï¼Œå›´ç»•ä¼ä¸šå®é™…éœ€æ±‚ï¼Œç²¾å¿ƒç»„ç»‡å®‰æ’æœ‰ç‰¹è‰²ã€æ¥åœ°æ°”çš„å®£ä¼ æ´»åŠ¨ã€‚åšæŒä¼ ç»Ÿæ–¹å¼ä¸ç°ä»£åŒ–æ‰‹æ®µç›¸ç»“åˆï¼ŒåŠ å¼ºä»¥æ¡ˆæ™®æ³•ï¼ŒåŠ å¼ºäººå·¥æ™ºèƒ½ã€å¤§æ•°æ®ã€çŸ­è§†é¢‘ç­‰æ–°æŠ€æœ¯æ–°åª’ä½“çš„è¿ç”¨ï¼Œä¸æ–­æå‡å®£ä¼ çš„äº’åŠ¨æ€§ã€ç²¾å‡†æ€§å’Œæœ‰æ•ˆæ€§ã€‚åšå†³åå¯¹å½¢å¼ä¸»ä¹‰ã€å®˜åƒšä¸»ä¹‰ï¼ŒåšæŒåœ¨ç”¨å¿ƒç”¨æƒ…æœåŠ¡ä¼ä¸šä¸­å¼€å±•æ³•æ²»å®£ä¼ ï¼Œä¸å¹²æ‰°ä¼ä¸šæ­£å¸¸ç”Ÿäº§ç»è¥ç§©åºï¼Œä¸ç»™ä¼ä¸šå’ŒåŸºå±‚å¢åŠ è´Ÿæ‹…ã€‚\n",
      "\n",
      "Source: {}\n",
      "Content: å…¨å›½æ™®æ³•åŠå…³äºå°å‘ã€Š2025å¹´â€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€å·¥ä½œæ–¹æ¡ˆã€‹çš„é€šçŸ¥å„çœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚å…šå§”å®£ä¼ éƒ¨ã€å¸æ³•å…ï¼ˆå±€ï¼‰ã€æ™®æ³•åŠï¼Œæ–°ç–†ç”Ÿäº§å»ºè®¾å…µå›¢å…šå§”å®£ä¼ éƒ¨ã€å¸æ³•å±€ã€æ™®æ³•åŠï¼Œä¸­å¤®å’Œå›½å®¶æœºå…³å„éƒ¨å§”æ™®æ³•åŠï¼šç°å°†ã€Š2025å¹´â€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€å·¥ä½œæ–¹æ¡ˆã€‹å°å‘ä½ ä»¬ï¼Œè¯·è®¤çœŸæ‰§è¡Œã€‚å„åœ°å¼€å±•â€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€æ´»åŠ¨æƒ…å†µï¼Œè¯·åŠæ—¶æŠ¥å…¨å›½æ™®æ³•åŠã€‚ä¸­å¤®å®£ä¼ éƒ¨å¸æ³•éƒ¨å…¨å›½æ™®æ³•åŠ2025å¹´4æœˆ18æ—¥ï¼ˆæ­¤ä»¶å…¬å¼€å‘å¸ƒï¼‰2025å¹´â€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€å·¥ä½œæ–¹æ¡ˆ2025å¹´5æœˆæ˜¯ç¬¬äº”ä¸ªâ€œæ°‘æ³•å…¸å®£ä¼ æœˆâ€ã€‚ä¸­å¤®å®£ä¼ éƒ¨ã€å¸æ³•éƒ¨ã€å…¨å›½æ™®æ³•åŠå°†ä»¥â€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€ä¸ºé‡ç‚¹ï¼Œç»„ç»‡å¼€å±•æ°‘æ³•å…¸ç³»åˆ—æ™®æ³•å®£ä¼ ã€‚ç°åˆ¶å®šå·¥ä½œæ–¹æ¡ˆå¦‚ä¸‹ã€‚ä¸€ã€æ€»ä½“è¦æ±‚åšæŒä»¥ä¹ è¿‘å¹³æ–°æ—¶ä»£ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ€æƒ³ä¸ºæŒ‡å¯¼ï¼Œå…¨é¢è´¯å½»è½å®å…šçš„äºŒåå¤§å’ŒäºŒåå±ŠäºŒä¸­ã€ä¸‰ä¸­å…¨ä¼šç²¾ç¥ï¼Œæ·±å…¥å­¦ä¹ å®£ä¼ è´¯å½»ä¹ è¿‘å¹³æ³•æ²»æ€æƒ³ï¼Œè®¤çœŸè´¯å½»è½å®ä¹ è¿‘å¹³æ€»ä¹¦è®°åœ¨æ°‘è¥ä¼ä¸šåº§è°ˆä¼šä¸Šçš„é‡è¦è®²è¯ç²¾ç¥ï¼Œå¹¿æ³›å¼€å±•â€œæ°‘æ³•å…¸è¿›ä¼ä¸šâ€æ´»åŠ¨ï¼Œå…¨é¢æé«˜ä¼ä¸šè¯šä¿¡å®ˆæ³•ç»è¥æ„è¯†å’Œèƒ½åŠ›ï¼ŒåŠ©åŠ›ä¼ä¸šé˜²èŒƒåŒ–è§£é£é™©ã€ä¾æ³•ç»´æŠ¤è‡ªèº«åˆæ³•æƒç›Šï¼Œä¸ºä¿ƒè¿›ç»æµé«˜è´¨é‡å‘å±•è¥é€ è‰¯å¥½æ³•æ²»ç¯å¢ƒã€‚äºŒã€å®£ä¼ é‡ç‚¹çªå‡ºå­¦ä¹ å®£ä¼ ä¹ è¿‘å¹³æ³•æ²»æ€æƒ³ï¼›æ·±å…¥å­¦ä¹ å®£ä¼ æ°‘æ³•å…¸ï¼Œé‡ç‚¹å­¦ä¹ å®£ä¼ å¹³ç­‰ã€è‡ªæ„¿ã€å…¬å¹³ã€è¯šä¿¡ç­‰åŸºæœ¬åŸåˆ™\n",
      "Agent å›å¤: æ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n",
      "\n",
      "1. **åŠ å¼ºç»„ç»‡é¢†å¯¼å’ŒååŒé…åˆï¼š** å…šå§”å®£ä¼ éƒ¨å’Œå¸æ³•è¡Œæ”¿éƒ¨é—¨è¦å‘æŒ¥ç‰µå¤´ä½œç”¨ï¼Œä¸è¡Œä¸šä¸»ç®¡éƒ¨é—¨åè°ƒé…åˆï¼Œç¡®ä¿æ°‘æ³•å…¸å®£ä¼ å·¥ä½œè½å®è½ç»†ã€‚\n",
      "2. **è½å®æ™®æ³•è´£ä»»ï¼š** è®¤çœŸè½å®é¢†å¯¼å¹²éƒ¨åº”çŸ¥åº”ä¼šå…šå†…æ³•è§„å’Œå›½å®¶æ³•å¾‹æ¸…å•åˆ¶åº¦ã€â€œè°æ‰§æ³•è°æ™®æ³•â€æ™®æ³•è´£ä»»ï¼Œä»¥åŠåª’ä½“å…¬ç›Šæ™®æ³•è´£ä»»ã€‚\n",
      "3. **å‘æŒ¥å„ç±»åŠ›é‡ï¼š** å……åˆ†å‘æŒ¥è¡Œä¸šåä¼šã€å•†ä¼šã€æ³•å¾‹æ˜ç™½äººã€æ™®æ³•è®²å¸ˆå›¢ã€æ™®æ³•å¿—æ„¿è€…ç­‰å…¬ç›Šæ™®æ³•é˜Ÿä¼çš„ä½œç”¨ï¼Œå½¢æˆå…±åŒè¡ŒåŠ¨çš„æ ¼å±€ã€‚\n",
      "4. **åˆ›æ–°å®£ä¼ æ–¹å¼ï¼š** åšæŒâ€œå°åˆ‡å£ã€å¤§ä¸»é¢˜â€ï¼Œå›´ç»•ä¼ä¸šå®é™…éœ€æ±‚ï¼Œç²¾å¿ƒç»„ç»‡å®£ä¼ æ´»åŠ¨ã€‚ç»“åˆä¼ ç»Ÿæ–¹å¼å’Œç°ä»£åŒ–æ‰‹æ®µï¼ŒåŠ å¼ºä»¥æ¡ˆæ™®æ³•ï¼Œè¿ç”¨æ–°æŠ€æœ¯æ–°åª’ä½“æå‡å®£ä¼ æ•ˆæœã€‚\n",
      "5. **æ³¨é‡æœåŠ¡ä¼ä¸šï¼š** åšæŒåœ¨æœåŠ¡ä¼ä¸šä¸­å¼€å±•æ³•æ²»å®£ä¼ ï¼Œä¸å¹²æ‰°ä¼ä¸šæ­£å¸¸ç”Ÿäº§ç»è¥ç§©åºï¼Œä¸å¢åŠ ä¼ä¸šè´Ÿæ‹…ã€‚\n",
      "6. **é‡ç‚¹å®£ä¼ å†…å®¹ï¼š** çªå‡ºå­¦ä¹ å®£ä¼ ä¹ è¿‘å¹³æ³•æ²»æ€æƒ³å’Œæ°‘æ³•å…¸ï¼Œé‡ç‚¹å¼ºè°ƒå¹³ç­‰ã€è‡ªæ„¿ã€å…¬å¹³ã€è¯šä¿¡ç­‰åŸºæœ¬åŸåˆ™ã€‚\n",
      "\n",
      "æ€»è€Œè¨€ä¹‹ï¼Œæ°‘æ³•å…¸è¿›ä¼ä¸šå·¥ä½œè¦æ±‚æ˜¯ç³»ç»Ÿæ€§çš„ï¼Œéœ€è¦å„æ–¹å…±åŒåŠªåŠ›ï¼Œä»¥å®é™…è¡ŒåŠ¨æé«˜ä¼ä¸šä¾æ³•ç»è¥çš„æ„è¯†å’Œèƒ½åŠ›ã€‚\n",
      "\n"
     ]
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
